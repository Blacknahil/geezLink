{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Creation of Amharic Triplet Dataset \n",
    "\n",
    "AmQA Dataset USED\n",
    "\n",
    "Initial AmQA Dataset: \n",
    "https://github.com/semantic-systems/amharic-qa\n",
    "\n",
    "Author: Abdulmunim J. Jemal\n",
    "\n",
    "Addis Ababa Institute of Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "We transformed the original QA dataset into two types of triplet datasets:\n",
    "\n",
    "### 1. **Context-Based Triplets**\n",
    "- **Anchor**: Question\n",
    "- **Positive**: Context containing the correct answer\n",
    "- **Negatives**: Contexts from other answers (sampled randomly)\n",
    "- **Use Case**: Useful for tasks like passage retrieval or contrastive learning.\n",
    "\n",
    "### 2. **Answer-Based Triplets**\n",
    "- **Anchor**: Question\n",
    "- **Positive**: Correct answer text\n",
    "- **Negatives**: Answers from other questions (sampled randomly)\n",
    "- **Use Case**: Ideal for question-answer matching or distractor generation.\n",
    "\n",
    "#### Key Steps:\n",
    "1. **Data Validation**: Ensured the dataset schema was correct and filtered invalid entries.\n",
    "2. **Grouping**: Grouped contexts or answers for efficient sampling.\n",
    "3. **Triplet Generation**: Created triplets by pairing questions with their positives and sampling negatives from unrelated contexts/answers.\n",
    "4. **Flexibility**: Added a `mode` parameter to switch between the two approaches.\n",
    "5. **Save**: Finally, saved both.\n",
    "\n",
    "**Note:** For our usecase, we will focus on context-based triplets.\n",
    "\n",
    "This modular pipeline ensures clean, reusable, and schema-compliant triplet generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "path = './amqa_data/'\n",
    "files = ['dev_data.json', 'test_data.json', 'train_data.json']\n",
    "\n",
    "def load_data(files=files, path=path):\n",
    "    data = {}\n",
    "    for file in files:\n",
    "        with open(os.path.join(path, file)) as f:\n",
    "            data[file.split('_')[0]] = json.load(f)\n",
    "    return data\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_json_skeleton(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {key: get_json_skeleton(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [get_json_skeleton(data[0]) if data else []]\n",
    "    else:\n",
    "        # Replace with a generic placeholder for scalar values\n",
    "        return type(data).__name__.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'paragraphs': [{'qas': [{'question': 'str',\n",
       "       'id': 'int',\n",
       "       'answers': [{'answer_id': 'int',\n",
       "         'document_id': 'int',\n",
       "         'question_id': 'int',\n",
       "         'text': 'str',\n",
       "         'answer_start': 'int',\n",
       "         'answer_end': 'int',\n",
       "         'answer_category': 'nonetype'}],\n",
       "       'is_impossible': 'bool'}],\n",
       "     'context': 'str',\n",
       "     'document_id': 'int'}]}],\n",
       " 'version': 'str'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert get_json_skeleton(data['train']) == get_json_skeleton(data['dev']) == get_json_skeleton(data['test'])\n",
    "get_json_skeleton(data['dev'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Load and Validate Data\n",
    "\n",
    "from typing import Dict, List, Any, Literal\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path: str) -> Dict:\n",
    "    \"\"\"Load JSON data from file with validation\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if \"data\" not in data:\n",
    "        raise ValueError(f\"Invalid file format in {file_path}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_extract_qa(raw_data: Dict) -> List[Dict]:\n",
    "    \"\"\"Validate schema and extract QA pairs with strict type checking\"\"\"\n",
    "    qa_list = []\n",
    "    \n",
    "    for document in raw_data[\"data\"]:\n",
    "        try:\n",
    "            for paragraph in document.get(\"paragraphs\", []):\n",
    "                context = paragraph.get(\"context\", \"\")\n",
    "                for qa in paragraph.get(\"qas\", []):\n",
    "                    # Validate question structure\n",
    "                    if not all(key in qa for key in [\"question\", \"id\", \"answers\"]):\n",
    "                        continue\n",
    "                    \n",
    "                    # Skip unanswerable questions\n",
    "                    if qa.get(\"is_impossible\", True):\n",
    "                        continue\n",
    "                    \n",
    "                    # Validate answer structure\n",
    "                    valid_answers = []\n",
    "                    for ans in qa[\"answers\"]:\n",
    "                        if all(k in ans for k in [\"text\", \"answer_start\", \"answer_end\"]):\n",
    "                            valid_answers.append(ans)\n",
    "                    \n",
    "                    if valid_answers:\n",
    "                        qa_list.append({\n",
    "                            \"question\": qa[\"question\"],\n",
    "                            \"answer\": valid_answers[0][\"text\"],\n",
    "                            \"question_id\": qa[\"id\"],\n",
    "                            \"context\": context,\n",
    "                            \"document_id\": paragraph[\"document_id\"]\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Triplet Generation Core\n",
    "# --------------------------\n",
    "def build_answer_answer_map(qa_list: List[Dict]) -> Dict[int, str]:\n",
    "    \"\"\"Create mapping of question_id -> correct answer\"\"\"\n",
    "    return {qa[\"question_id\"]: qa[\"answer\"] for qa in qa_list}\n",
    "\n",
    "def generate_answer_triplets(\n",
    "    qa_list: List[Dict],\n",
    "    num_negatives: int = 3\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Generate (question, correct_answer, other_answers) triplets\"\"\"\n",
    "    answer_map = build_answer_answer_map(qa_list)\n",
    "    all_answers = list(answer_map.values())\n",
    "    question_ids = list(answer_map.keys())\n",
    "    \n",
    "    triplets = []\n",
    "    for qa in qa_list:\n",
    "        current_id = qa[\"question_id\"]\n",
    "        current_answer = qa[\"answer\"]\n",
    "        \n",
    "        # Get answers from other questions\n",
    "        negative_pool = [\n",
    "            ans for qid, ans in answer_map.items()\n",
    "            if qid != current_id\n",
    "        ]\n",
    "        \n",
    "        # Deduplicate and sample\n",
    "        unique_negatives = list(set(negative_pool))\n",
    "        sampled_negatives = random.sample(\n",
    "            unique_negatives,\n",
    "            min(num_negatives, len(unique_negatives))\n",
    "        )\n",
    "        \n",
    "        triplets.append({\n",
    "            \"anchor\": qa[\"question\"],\n",
    "            \"positive\": current_answer,\n",
    "            \"negatives\": sampled_negatives\n",
    "        })\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplet\n",
    "\n",
    "def generate_contrastive_triplets(\n",
    "    qa_list: List[Dict],\n",
    "    answer_context_map: Dict[str, List[str]],\n",
    "    num_negatives: int = 3\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Generate (anchor, positive, negatives) triplets.\"\"\"\n",
    "    triplets = []\n",
    "    \n",
    "    for qa in qa_list:\n",
    "        anchor = qa[\"question\"]\n",
    "        positive = qa[\"context\"]\n",
    "        answer = qa[\"answer\"]\n",
    "        \n",
    "        # Collect all contexts from other answers as negatives\n",
    "        negative_pool = [\n",
    "            ctx \n",
    "            for ans, ctx_list in answer_context_map.items() \n",
    "            if ans != answer\n",
    "            for ctx in ctx_list\n",
    "        ]\n",
    "        \n",
    "        # Deduplicate and sample negatives\n",
    "        unique_negatives = list(set(negative_pool))\n",
    "        sampled_negatives = random.sample(\n",
    "            unique_negatives, \n",
    "            min(num_negatives, len(unique_negatives))\n",
    "        )\n",
    "        \n",
    "        triplets.append({\n",
    "            \"anchor\": anchor,\n",
    "            \"positive\": positive,\n",
    "            \"negatives\": sampled_negatives\n",
    "        })\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Unified Interface\n",
    "# --------------------------\n",
    "def generate_triplets_from_file(\n",
    "    file_path: str,\n",
    "    num_negatives: int = 3,\n",
    "    mode: Literal[\"context\", \"answer\"] = \"context\"\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Unified triplet generator with mode switching\n",
    "    - 'context' mode: (question, context, other_contexts)\n",
    "    - 'answer' mode: (question, correct_answer, other_answers)\n",
    "    \"\"\"\n",
    "    raw_data = load_json(file_path)\n",
    "    qa_list = validate_and_extract_qa(raw_data)\n",
    "    \n",
    "    if mode == \"context\":\n",
    "        # Original context-based implementation\n",
    "        answer_context_map = build_answer_context_map(qa_list)\n",
    "        return generate_contrastive_triplets(qa_list, answer_context_map, num_negatives)\n",
    "    elif mode == \"answer\":\n",
    "        # New answer-based implementation\n",
    "        return generate_answer_triplets(qa_list, num_negatives)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {mode}. Choose 'context' or 'answer'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two modes; \n",
    "# question - right context - wrong context\n",
    "# question - right answer - wrong answers\n",
    "train_context_triplets = generate_triplets_from_file(\"amqa_data/train_data.json\", num_negatives=5)\n",
    "train_answer_triplets = generate_triplets_from_file(\"amqa_data/train_data.json\", num_negatives=5, mode=\"answer\")\n",
    "\n",
    "dev_context_triplets = generate_triplets_from_file(\"amqa_data/dev_data.json\", num_negatives=5)\n",
    "dev_answer_triplets = generate_triplets_from_file(\"amqa_data/dev_data.json\", num_negatives=5, mode=\"answer\")\n",
    "\n",
    "test_context_triplets = generate_triplets_from_file(\"amqa_data/test_data.json\", num_negatives=5)\n",
    "test_answer_triplets = generate_triplets_from_file(\"amqa_data/test_data.json\", num_negatives=5, mode=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Train Context Triplets: 1343\n",
      "Train Answer Triplets: 1343\n",
      "Dev Context Triplets: 504\n",
      "Dev Answer Triplets: 504\n",
      "Test Context Triplets: 288\n",
      "Test Answer Triplets: 288\n"
     ]
    }
   ],
   "source": [
    "print(\"Results:\")\n",
    "print(f\"Train Context Triplets: {len(train_context_triplets)}\")\n",
    "print(f\"Train Answer Triplets: {len(train_answer_triplets)}\")\n",
    "print(f\"Dev Context Triplets: {len(dev_context_triplets)}\")\n",
    "print(f\"Dev Answer Triplets: {len(dev_answer_triplets)}\")\n",
    "print(f\"Test Context Triplets: {len(test_context_triplets)}\")\n",
    "print(f\"Test Answer Triplets: {len(test_answer_triplets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Context Triplets\n",
      "{\n",
      "  \"anchor\": \"የታክስ ገቢ ከ2010-2012 በመቶኛ የምን ያህል መጠን እድገት አሳየ?\",\n",
      "  \"positive\": \"ጠቅላይ ሚኒስትር ዐቢይ አሕመድ ከ2010 ጀምሮ በፋይናንሱ ዘርፍ ስኬታማ ለውጦች መመዝገባቸውን ገለጹ፡፡ ጠቅላይ ሚኒስትር ዐቢይ የፋይናንስ ዘርፍ ዐበይት ስኬቶች በሚል በማህበራዊ ትስስር ገፃቸው ላይ እንዳስታወቁት የታክስ ገቢ በ2010 ከነበረበት 229 ቢሊየን ብር በ2012 የ36 በመቶ ጭማሪ በማሳየት 311 ቢሊየን ማድረስ ተችሏል።\",\n",
      "  \"negatives\": [\n",
      "    \"ፋሲለደስ ዓፄ ፋሲለደስ ወይም ዓፄ ፋሲል (የዙፋን ስማቸው ዓለም ሰገድ)  ከአባታቸው አፄ ሱሰኒዮስ  እና እናታቸው ልዕልት ስልጣነ ምገሴ  በመገዛዝ፣ ሸዋ ህዳር 10፣ 1603  (እ.ኤ.አ) ተወለዱ። የነገሱበትም ዘመን ከ1632  እስከ ጥቅምት 18, 1667 (እ.ኤ.አ) ነበር። በስረፀ ክርስቶስ በተመራው አመፅ ምክንያት በ1630 ፋሲለደስ ለንግስና ቢበቃም፣ ዘውዱን ግን እስከ 1632 አልጫነም ነበር። ሲመተ ንግስናው በ1632 እንደተገባደደ የመጀመሪያው ስራው የተዋህዶ ቤ/ክርስቲያንን የቀድሞው ቁመና መመለስና የካቶሊኮችን መሬት በመቀማት ከደንካዝ በማባረር በፍሪሞና እንዲወሰኑ ማድረግ ነበር። ወዲያውም በማከታተል ከግብፅ አገር አዲስ ጳጳስ እንዲላክለት በማድረግ በአባቱ ዘመን እንዲደበዝዝ ተደርጎ የነበረውን የግብፅና ኢትዮጵያ አብያተ ክርስቲያናት ግንኙነት እንዲጸና አደረገ።  በኬኒያ የሚገኘው የሞምባሳ ወደብ በፖርቱጋሎች መደብደቡን ሲሰማ፣ የሮማው ፓፓ ከበስትጀርባው ያለበት ሴራ ነው በማለት በምድሩ የነበሩትን የካቶሊክ ጀስዊቶች በመሰብሰብ አባረራቸው። አፄ ፋሲል አዘዞ ተብላ በምትታወቀው ከጎንደር ከተማ 5 ማይል ርቃ በምትገኘው ከተማ ጥቅምት18፣1667 እ.ኤ.አ. (ጥቅምት 10፣ 1660) ከዚህ አለም በሞት ተለዩ። አስከሬናቸውም የአገሪቱ መላ ህዝብ ባዘነበት ሁኔታ በቅዱስ እስጢፋኖስ ገዳም፣ ጣና ሃይቅ ውስጥ ደጋ ደሴት ተብላ በምትታወቀው ደሴት የዘላለም እረፍት አገኘ።\",\n",
      "    \" የቻይና ተመራማሪዎች እጅግ በጣም ከፍተኛ በሆነ የሙቀት ወቅት የአውሮፕላኖችን ሁኔታ መከታተል የሚያስችል ዘዴ ይፋ አደረጉ። አዲሱ ቴክኖሎጂ አውሮፕላኖች ከ800 እስከ 1 ሺህ 300 ዲግሪ ሴሊሺየስ ባለው የሙቀት መጠን ውስጥ ሲሰሩ በአውሮፕላኖቹ ውስጥ የሚከሰተውን መዋቅራዊ ብልሽት መለየት የሚያስችል መሆኑን ተመራማሪዎቹ ገልጸዋል። ይህም እጅግ ከፍተኛ የሆነ ሙቀትና ቅዝቃዜ ባለበት የአየር ንብረት ውስጥ የሚንቀሳቀሱ አውሮፕላኖችን አጠቃላይ ሁኔታ ለመከታተል የሚያግዝ ነው ተብሏል። ከዚህ ባለፈም አውሮፕላኑ በከፍተኛ ፍጥነት በሚበርበት ወቅት የሚያጋጥመውን ከፍተኛ ሙቀት ተቋቁሞ በረራውን መቀጠል ስለመቻል አለመቻሉም ለመወሰን እንደሚያግዝም ከተመራማሪዎቹ አንዱ የሆኑት ዋንግ ዚዮንግ ተናግረዋል። የአውሮፕላኖች አሰራር እጅግ ከፍተኛ በሆነ የሙቀት መጠን ውስጥ የሚደረግን በረራ መቋቋም ስለመቻል አለመቻሉ በመወሰን አዲስ ለሚሰራ የአውሮፕላን ንድፍ እንደ ማጣቀሻ ሆኖ ያገለግላልም ነው የተባለው። ከዚህ አንጻርም የአውሮፕላን አካላትን ንድፍ ለማሻሻል እንዲሁም ቀላል እና ብዙ ጭነቶችን መሸከም የሚችሉ አውሮፕላኖችን ለመስራት በሚደረገው ጥረት አስተዋጽኦ ሊኖረው እንደሚችልም ተገልጿል። ምንጭ፦ ሲ ጂ ቲ ኤን\",\n",
      "    \"አዋሽ ብሔራዊ የመዝናኛ እና የዱር አራዊት ጥበቃ ክልል የአዋሽ ብሔራዊ መዝናኛ እና የዱር አራዊት ጥበቃ ክልል በ፲፱፻፶፰ ዓ/ም የተመሠረተ ክልል ሲሆን ከአዲስ አበባ በስተ ምሥራቅ አቅጣጫ በ፪መቶ ፲፩ ኪሎሜትር ርቀት ፤  በአፋርና በኦሮሚያ አዋሳኝ ክልሎች ሥር ይገኛል። ይህ ክልል ሲመሠረት በ ፱፻፮ ካሬ ኪሎሜትር የቆዳ ስፋት (ቦልቶን ፲፱፻፷፰) የነበረው ቢሆንም፤ ባሁኑ ጊዜ የኢትዮጵያ የዱር እንስሳት ልማትና ጥበቃ ባለሥልጣን ማስረጃ እንዳስቀመጠው የክልሉ የቆዳ ስፋት ፯መቶ ፶፮ ካሬ ኪሎ-ሜትር ነው። የክልሉ ደቡባዊ ድንበር የአዋሽ ወንዝ ሲሆን፣ የተሠየመውም በዚሁ ታላቅ ወንዝ ስም ነው። ክልሉ የብዙ ዓይነት አራዊት እና አዕዋፍ መጠለያ ከመሆኑም ባሻገር ፍል-ውሓ እና የፋንታሌ ተራራ ይገኙበታል። የአገሪቱ  የዱር አራዊት ጥበቃ ባለ-ሥልጣን ሲመሠረት ለንጉሠ ነገሥቱ መንግሥት በአማካሪነት የተመደበው እንግሊዛዊ ባቀረበው ኃሣብ መሠረት የመጀመሪያው ብሔራዊ የዱር አራዊት ጥበቃ ባለ-ሥጣን ከተመሠረተ በኋላ የቅድሚያ ሥራ የተደረገው፤ በታቀዱት ክልሎች የሚገኙትን የአገሪቱን የዱር አራዊት ኃብት መጠን ማረጋገጥ ነበር። ለዚህም ሥራ ከብሪታኒያ ተመልምሎ የተቀጠረው ባለ-ሙያ እንግሊዛዊው የሥነ-ሕይወት ባለሙያ ሜልቪን ቦልቶን ነበር። የአዋሽ ብሔራዊ መዝናኛ እና የዱር አራዊት ጥበቃ ክልል የበርካታ የዱር አራዊት፤ አዕዋፋት እና የውሐ አራዊት መኖሪያ ነው። በደቡብ አዋሳኙ በሆነው የአዋሽ ወንዝ አዞ እና ጉማሬ ሲገኝበት፤ በሰሜን ክፍሉ ደግሞ ጦጣና ዝንጀሮ፤ እንዲሁም ጅብ እና አጋዘን ይገኙበታል። በክልሉ ከሚገኙት የዱር አራዊት በከፊሉ፦ ጉሬዛ፤ ተራ ዝንጀሮ፤ ነጭ ዝንጀሮ፤ ጦጣ፤ ሳላ፤ የሜዳ ፍየል፤ ሚዳቋ፤ ትልቁ የቆላ አጋዘን ፤ አምባራይሌ፤ ከርከሮ፤ ቆርኪ በብዛት የሚገኙ ሲሆን አንበሣ፤ ነብር፤ ጀርባ-ጥቁር እና ተራ ቀበሮ፤ዳልጋ አንበሣ፤ አነር እና የዱር ድመት ደግም አልፎ-አልፎ ይታያሉ። ባለፉት አሥር ዓመታት ጊዜ ውስጥ በተካሄደ ምዝገባ እንደተረጋገጠው፣ በክልሉ ውስጥ ፬መቶ ፷፪ ዓይነት የወፍ ዝርያዎች ተመዝግበዋል። ከነዚህም መኻል ስድስቱ በኢትዮጵያ ውስጥ ብቻ የሚገኙ ናቸው። እነዚህም መንቆረ-ጥቁር ጋርደም፤ ግንደ-ቆርቁር፤ ክንፈ-ነጭ የገደል-ቻት፤ ጅራተ-ረጅም ወማይ፤ ቁራ እና ጋጋኖ ናቸው።\",\n",
      "    \"መስከረም 23/12 ዓ ም ሽሬ ኢዜአ  የተለያዩ የፈጠራ ውጤቶችን ለተጠቃሚዎች በማቅረብ ይሁንታ ያገኘው የ35 ዓመት ወጣት ሔሊኮፕተር ሰርቶ ለሙከራ እየተዘጋጀ መሆኑን አስታወቀ ። ወጣት ዕበ ለገሰ ይባላል ። በመደበኛ ትምህርት ብዙ ገፍቶ ባይሔድም በፈጣራ ብቃቱ ግን በርካታ ስራዎች ለህዝብ እንዲያደርስ አድርጎታል ። የ10ኛ ክፍል ትምህርቱን እንዳጠናቀቀ በኤሌክትሪክ ሃይል የሚሰራ ምጣድ ጥገና ሥራ የጀመረው ወጣት አሁን ላይ ትልቅ ራእይ አንግቦ የራሱ የሆኑ የፈጠራ ስራዎችን በማቅረብ ውጤታማነቱን በተጠቃሚዎች ዘንድ እየተመሰከረለት መጥቷል ። የምጣድ ጥገና ስራው ለታናሽ ወንድሙ በመልቀቅ የወርቅ መአድን መፈለጊያ መሳሪያ ወደ ማሻሻል መሸጋገሩን ይገልፃል ። በራሱ ፈጠራ ያሻሻለው የወርቅ መፈለጊያ መሳሪያ በባህላዊ መንገድ ወርቅ ለሚያመርቱ ሰዎች በሽያጭ በማቅረብ የፍለጋ ሥራቸውን እንዲቃለል እንዳስቻላቸው ተጠቃሚዎቹ ይናገራሉ ። ቀደም ሲል የነበረው ‘’ጂ አር ዜድ’’ የተባለው የወርቅ መፈለጊያ መሳሪያ ከ70 እስከ 80 ሳንቲ ሜትር ጥልቀት ባለው መሬት ውስጥ የሚገኝ የደለል ወርቅ የሚጠቁም ነበር ። ወጣቱ ያሻሸለው ግን በአንድ ሜትር ጥልቀት የሚገኘውን የደለል ወርቅ በቀላሉ መለየት የሚያስችል መሳርያ ሆኖ ተገኝቷል ። እንዲሁም ከድንጋይ ጋር ተደባልቆ የሚገኝ ወርቅ በቀላሉ መለየት የሚያስችል የድንጋይ ወፍጮ በመፍጠር ለተጠቃሚዎቹ በማቅረብ ላይ እንደሚገኝም ወጣት  ለገሰ ይናገራል ። ባለፉት አምስት ዓመታት አምስት የድንጋይ ወፍጮዎችን በመስራት ለተጣቀሚዎቹ በተመጣጣኝ ዋጋ አቅርቧል ። በተጠናቀቀው ዓመት በራሱ ፈጠራ ሶስት ሰዎች የማሳፈር አቅም ያለት ሔሊኮፕተር ሰርቶ በሙከራ ደረጃ ለህዝብ እይታ አቅርቦ የነበረው ወጣቱ ዘንድሮ ለማብረር እየተዘጋጀ መሆኑንም ተናግሯል ። የፈጠራ ሥራዬ ስኬትና ሚስጥር “ይቻላል” የሚል ጽኑ እምነት ስላለኝ ነው የሚለው ወጣቱ ከኢንተርኔት የሚያገኛቸው የፈጠራ ሥራዎችም እገዛ እንዳደረጉለት ጠቁሟል። ሥራ ፈጣሪ ወጣቱ ወደ ገበያ በሚያቀርባቸው የፈጠራ ውጤቱ ጥሩ ገቢ ከማግኘቱም ባሻገር ለሌሎች 10 ወጣቶች የስራ እድል መፍጠሩን ተናግሯል። የወጣቱ የፈጠራ ወጤት ተጠቃሚ ከሆኑትና በባህላዊ መንገድ በደለል ወርቅ ምርት ፍለጋ ከተሰማሩ ማህበራት መካከል የ“ስምረት” ማህበር አንዱ ነው። የማህበሩ አባል የሆነው ወጣት በላይ ተክለሃይማኖት በሰጠው አስተያየት ” ከወጣቱ የገዛነው የደለል ወርቅ ጠቋሚ መሳርያ ሥራችንን ከማቃለል በተጨማሪ በወርቅ ፍለጋው ስኬታማ እንድንሆን አግዞናል” ብሏል። ሌላው የማህበሩ አባል ወጣት ተስፋይ በላይ በበኩሉ ” ከድንጋይ ጋር ተደባልቆ የሚገኝ ወርቅ ለመለየት እጅግ አድካሚ የነበረው ሥራ ወጣቱ ባቀረበልን አነስተኛ የድንጋይ ወፍጮ በመጠቀም የድካማችንን ዋጋ ማግኘት አስችሎናል ” በማለት አድናቆቱን ገልፆለታል ። የሽሬ እንዳስላሴ ከተማ የወጣቶችና ስፖርት ጉዳይ ጽህፈት ቤት ምክትል ሃላፊ አቶ ጎይቶኦም ይሰማ እንዳሉትም ደግሞ የወጣቱን የፈጠራ ክህሎት እንዲሰፋና ሄሊኮፕተሯ ለህዝብ እይታ እንድትበቃ አስፈላጊውን ድጋፍ ይደረግለታል ። የሽሬ እንደስላሴ ፖሊ ቴክኒክና ኮሌጅ ዲን አቶ ፀጋይ ገብረሚካኤል በበኩላቸው የፈጠራ ባለቤት የሆነው ወጣት እበ ለገሰ የፈጠራ ስራዎች የሚያተኩሩት በአካባቢው ህብረተሰብ ላይ በሚታዩ መሰረታዊ ችግሮች ዙሪያ በመሆናቸው ተቀባይነታቸው የጎላ ነው ብለዋል ። ወጣቱ የሚያሳየው ትጋት የተሞላበት የፈጠራ ስራ ለሌሎች ወጣቶችም አርአያ በመሆን መነቃቃት መፍጠሩን የኮሌጁ ዲን መስክረውለታል ።      \",\n",
      "    \"ተቀማጭነቱ ካሊፎርኒያ ውስጥ ያደረገው ኢ ኦ ኤን ሪአሊቲ የተባለው የሶፍትዌር አምራች ኩባንያ በኢትዮጵያ ውስጥ ማዕከሉን የመክፈት ፍላጎት እንዳለው ገለጸ፡፡ የኢ ኦ ኤን ኩባንያ መስራች ዳን ለጀርስካር ከሳይንስና ከፍተኛ ትምህርት ሚኒስትር ፕሮፌሰር ሂሩት ወልደማርያም ጋር ውይይት ያደረጉ ሲሆን፣ ኩባንያው በኢትዮጵያ ማዕከሉን የመክፈት ፍላጎት መኖሩን ተናግረዋል፡፡ ፕሮፌሰር ሂሩት በበኩላቸው የቴክኖሎጂውን አስፈላጊነትና ወቅታዊነትን በመገንዘብ ሚኒስቴር መስሪያ ቤቱ ከኩባንያው ጋር በትብብር እንደሚሰራ ገልጸዋል፡፡\"\n",
      "  ]\n",
      "}\n",
      "Train - Answer Triplets\n",
      "{\n",
      "  \"anchor\": \"የታክስ ገቢ ከ2010-2012 በመቶኛ የምን ያህል መጠን እድገት አሳየ?\",\n",
      "  \"positive\": \"የ36 በመቶ\",\n",
      "  \"negatives\": [\n",
      "    \"በአዲስ አበባ ጎተራ አካባቢ\",\n",
      "    \"የሀዲያ ዞን\",\n",
      "    \"በስሚዝ ኮሌጅ\",\n",
      "    \"ቀዳማዊ ኃይለ ሥላሴ ዓለም አቀፍ አውሮፕላን ማረፊያ\",\n",
      "    \"ሌዙ\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example of each type of triplets. using json\n",
    "\n",
    "print(\"Train - Context Triplets\")\n",
    "print(json.dumps(train_context_triplets[0], indent=2, ensure_ascii=False))\n",
    "print(\"Train - Answer Triplets\")\n",
    "print(json.dumps(train_answer_triplets[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Save Triplets as CSV\n",
    "\n",
    "import csv\n",
    "def save_triplets_to_csv(triplets, file_path):\n",
    "    try:\n",
    "        with open(file_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=triplets[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(triplets)\n",
    "        print(f\"Saved {len(triplets)} triplets to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save triplets: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1343 triplets to data/train.csv\n",
      "Saved 504 triplets to data/dev.csv\n",
      "Saved 288 triplets to data/test.csv\n"
     ]
    }
   ],
   "source": [
    "folder = \"data\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# For our current usecase, the context triplets are more useful\n",
    "save_triplets_to_csv(train_context_triplets, f\"{folder}/train.csv\")\n",
    "save_triplets_to_csv(dev_context_triplets, f\"{folder}/dev.csv\")\n",
    "save_triplets_to_csv(test_context_triplets, f\"{folder}/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geezlink-WoNzkeoT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
